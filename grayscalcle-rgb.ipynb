{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport keras\nimport cv2\nfrom keras.layers import MaxPool2D,Conv2D,UpSampling2D,Input,Dropout\nfrom keras.models import Sequential\nfrom keras.utils import img_to_array\nimport os\nfrom tqdm import tqdm\nimport re\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#to sort the images \ndef sorted_alphanumeric(data):  \n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n    return sorted(data,key = alphanum_key)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIZE = 224\ncolor_img = []\npath = '/kaggle/input/landscape-image-colorization/landscape Images/color'\nfiles = os.listdir(path)\nfiles = sorted_alphanumeric(files)\nfor i in tqdm(files):    \n    if i == '1000.jpg':\n        break\n    else:    \n        img = cv2.imread(path + '/'+i,1)\n        # open cv reads images in BGR format so we have to convert it to RGB\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        #resizing image\n        img = cv2.resize(img, (SIZE, SIZE))\n        img = img.astype('float32') / 255.0\n        color_img.append(img_to_array(img))\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gray_img = []\npath = '/kaggle/input/landscape-image-colorization/landscape Images/gray'\nfiles = os.listdir(path)\nfiles = sorted_alphanumeric(files)\nfor i in tqdm(files):\n     if i == '1000.jpg':\n        break\n     else: \n        img = cv2.imread(path + '/'+i,1)\n\n        #resizing image\n        img = cv2.resize(img, (SIZE, SIZE))\n        img = img.astype('float32') / 255.0\n        gray_img.append(img_to_array(img))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_images(color,grayscale):\n    plt.figure(figsize=(15,15))\n    plt.subplot(1,3,1)\n    plt.title('Color Image', color = 'green', fontsize = 20)\n    plt.imshow(color)\n    plt.subplot(1,3,2)\n    plt.title('Grayscale Image ', color = 'black', fontsize = 20)\n    plt.imshow(grayscale)\n   \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(1,3):\n     plot_images(color_img[i],gray_img[i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gray_image = gray_img[:5500]\ntrain_color_image = color_img[:5500]\n\ntest_gray_image = gray_img[5500:]\ntest_color_image = color_img[5500:]\n# reshaping\ntrain_g = np.reshape(train_gray_image,(len(train_gray_image),SIZE,SIZE,3))\ntrain_c = np.reshape(train_color_image, (len(train_color_image),SIZE,SIZE,3))\nprint('Train color image shape:',train_c.shape)\n\n\ntest_gray_image = np.reshape(test_gray_image,(len(test_gray_image),SIZE,SIZE,3))\ntest_color_image = np.reshape(test_color_image, (len(test_color_image),SIZE,SIZE,3))\nprint('Test color image shape',test_color_image.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.layers import Input, Lambda, Dense, Flatten","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using vgg net for our encoder part\nIMAGE_SIZE=[224,224]\nvgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = Flatten()(vgg.output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in vgg.layers:\n    layer.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newmodel= Sequential() \nnewmodel.add(vgg)\nnewmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _vgg16(x):\n    vggfeatures = []\n    for i, sample in enumerate(x):\n        sample = sample.reshape((1,224,224,3))\n        prediction = newmodel.predict(sample)\n        prediction = prediction.reshape((7,7,512))\n        vggfeatures.append(prediction)\n        vggfeatures = np.array(vggfeatures)\n        return vggfeatures\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vggfetures_train=_vgg16(train_g)\nvggfetures_test=_vgg16(train_color_image)\n\nvggfetures_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(256, (3,3), activation='relu', padding='same', input_shape=(7,7,512)))\nmodel.add(Conv2D(128, (3,3), activation='relu', padding='same'))\nmodel.add(UpSampling2D((2, 2)))\nmodel.add(Conv2D(64, (3,3), activation='relu', padding='same'))\nmodel.add(UpSampling2D((2, 2)))\nmodel.add(Conv2D(32, (3,3), activation='relu', padding='same'))\nmodel.add(UpSampling2D((2, 2)))\nmodel.add(Conv2D(16, (3,3), activation='relu', padding='same'))\nmodel.add(UpSampling2D((2, 2)))\nmodel.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\nmodel.add(UpSampling2D((2, 2)))\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='Adam', loss='mse' , metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(vggfetures_train,vggfetures_test,verbose=1, epochs=10, batch_size=50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}